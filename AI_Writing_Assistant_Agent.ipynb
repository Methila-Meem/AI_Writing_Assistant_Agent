{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**\n",
        "\n",
        "Basic AI Writing Assistant Agent\n",
        "\n",
        "*   Designing and implementing an AI-powered agent that assists users with writing tasks.\n",
        "*   The agent helps to improve the quality of text by performing tasks such as grammar correction, vocabulary enhancement, and sentence rewriting.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YZLjn68EfsmB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing necessary packages"
      ],
      "metadata": {
        "id": "Orot0dOLgcoj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gwsP77jb9_l",
        "outputId": "cd665246-e861-4c1d-d27b-25d6bdb810a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (0.6.7)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.28)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.12/dist-packages (0.3.8)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.76)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.9)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.6.4)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.3)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.25.0)\n",
            "Requirement already satisfied: groq<1,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.31.1)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langgraph langsmith langchain-groq langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing necessary libraries"
      ],
      "metadata": {
        "id": "4yDKogTtgh7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from getpass import getpass\n",
        "from typing import List, Optional, TypedDict\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "5V6IUFmYfD6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up LLM with api"
      ],
      "metadata": {
        "id": "__P9Jb92gtcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_api_key= userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "n0-q65dKeoVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"deepseek-r1-distill-llama-70b\"\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=MODEL_NAME,\n",
        "    temperature=0.0,\n",
        "    max_tokens=None,\n",
        "    groq_api_key=groq_api_key\n",
        ")\n",
        "print(\"ChatGroq initialized (model =\", MODEL_NAME, \")\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upyZAWQBqtXY",
        "outputId": "5c7b8b6b-014f-451a-e720-a159f1dd8ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGroq initialized (model = deepseek-r1-distill-llama-70b )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HELPER: call Groq model\n",
        "def run_llm(system_prompt: str, user_prompt: str) -> str:\n",
        "    \"\"\"Call the ChatGroq model and return the assistant's text content.\"\"\"\n",
        "    messages = [(\"system\", system_prompt), (\"human\", user_prompt)]\n",
        "    ai_msg = llm.invoke(messages)\n",
        "    return ai_msg.content"
      ],
      "metadata": {
        "id": "SAIUC0TvhHws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STATE for LangGraph\n",
        "class AgentState(TypedDict):\n",
        "    text: str\n",
        "    tools_to_run: List[str]       # optional extras, e.g. [\"vocab\"]\n",
        "    tone: Optional[str]           # e.g. \"formal\"\n",
        "    final_output: Optional[str]   # not strictly required, but kept for clarity"
      ],
      "metadata": {
        "id": "vzRBVXbthgwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up tools"
      ],
      "metadata": {
        "id": "F9K-7yRjhTlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The assistant uses four tools:\n",
        "\n",
        "grammar_corrector – fixes grammar and punctuation.\n",
        "Always runs first.\n",
        "\n",
        "sentence_rewriter – improves clarity and flow.\n",
        "Always runs after grammar correction.\n",
        "\n",
        "vocab_enhancer – enriches word choice.\n",
        "Runs only if the user requests vocabulary enhancement.\n",
        "\n",
        "tone_adjuster – changes style (e.g., formal, casual).\n",
        "Runs only if the user provides a tone.\n",
        "\n",
        "Flow:\n",
        "grammar → rewrite → (vocab if requested) → (tone if specified)\n",
        "\n",
        "The LangGraph StateGraph enforces this order.\n",
        "Grammar and rewriting are mandatory for every input; vocabulary and tone steps depend solely on the user’s optional choices."
      ],
      "metadata": {
        "id": "vqddDFnpijPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NODES\n",
        "def grammar_node(state: AgentState):\n",
        "    system = \"You are a meticulous grammar and punctuation editor. Return ONLY the corrected text.\"\n",
        "    user   = f\"Correct grammar, punctuation, and minor phrasing while preserving meaning. Text:\\n\\n{state['text']}\"\n",
        "    return {\"text\": run_llm(system, user)}\n",
        "\n",
        "def rewrite_node(state: AgentState):\n",
        "    system = \"You are a helpful rewriter. Return ONLY the rewritten text focused on clarity and flow.\"\n",
        "    user   = f\"Rewrite the following to be clearer and better structured without changing meaning:\\n\\n{state['text']}\"\n",
        "    return {\"text\": run_llm(system, user)}\n",
        "\n",
        "def vocab_node(state: AgentState):\n",
        "    system = (\"You are an editor who improves vocabulary and clarity. \"\n",
        "              \"Return ONLY the improved text with better word choice while preserving meaning.\")\n",
        "    user   = f\"Improve vocabulary and clarity:\\n\\n{state['text']}\"\n",
        "    return {\"text\": run_llm(system, user)}\n",
        "\n",
        "def tone_node(state: AgentState):\n",
        "    tone = state.get(\"tone\", \"neutral\")\n",
        "    system = f\"You are a tone adjuster. Convert the text to a {tone} tone while preserving meaning. Return ONLY the adjusted text.\"\n",
        "    user   = f\"Adjust this text to {tone} tone:\\n\\n{state['text']}\"\n",
        "    return {\"text\": run_llm(system, user)}"
      ],
      "metadata": {
        "id": "TO-o-Lr_w48y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BUILDING THE GRAPH\n",
        "graph = StateGraph(AgentState)\n",
        "\n",
        "graph.add_node(\"grammar\", grammar_node)\n",
        "graph.add_node(\"rewrite\", rewrite_node)\n",
        "graph.add_node(\"vocab\", vocab_node)\n",
        "graph.add_node(\"tone\", tone_node)\n",
        "\n",
        "graph.set_entry_point(\"grammar\")\n",
        "graph.add_edge(\"grammar\", \"rewrite\")\n",
        "\n",
        "# After rewrite, decide if vocab or tone is requested\n",
        "graph.add_conditional_edges(\n",
        "    \"rewrite\",\n",
        "    lambda state: \"vocab\" if \"vocab\" in state.get(\"tools_to_run\", []) else (\"tone\" if state.get(\"tone\") else END),\n",
        "    {\"vocab\": \"vocab\", \"tone\": \"tone\", END: END}\n",
        ")\n",
        "\n",
        "# After vocab, maybe tone\n",
        "graph.add_conditional_edges(\n",
        "    \"vocab\",\n",
        "    lambda state: \"tone\" if state.get(\"tone\") else END,\n",
        "    {\"tone\": \"tone\", END: END}\n",
        ")\n",
        "\n",
        "graph.add_edge(\"tone\", END)\n",
        "\n",
        "app = graph.compile()\n"
      ],
      "metadata": {
        "id": "Y7jTJFB-xaBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== UTIL =====\n",
        "def strip_think_blocks(s: str) -> str:\n",
        "    \"\"\"Remove any <think>...</think> blocks that some models add.\"\"\"\n",
        "    return re.sub(r\"<think>.*?</think>\\s*\", \"\", s, flags=re.DOTALL).strip()\n",
        "\n",
        "# ===== CLI INTERACTION =====\n",
        "user_text = input(\"Enter a sentence or paragraph: \").strip()\n",
        "want_vocab = input(\"Add vocabulary enhancement? (y/n): \").strip().lower().startswith(\"y\")\n",
        "tone_req = input(\"Tone (leave blank for none, e.g. formal/casual): \").strip() or None\n",
        "\n",
        "initial_state: AgentState = {\n",
        "    \"text\": user_text,\n",
        "    \"tools_to_run\": [\"vocab\"] if want_vocab else [],\n",
        "    \"tone\": tone_req,\n",
        "    \"final_output\": None\n",
        "}\n",
        "\n",
        "result = app.invoke(initial_state)\n",
        "final_text = strip_think_blocks(result[\"text\"])\n",
        "\n",
        "print(\"\\nImproved sentence:\\n\", final_text)\n",
        "\n",
        "print(\"\\nSteps executed:\")\n",
        "print(\" - grammar_corrector\")\n",
        "print(\" - sentence_rewriter\")\n",
        "if want_vocab:\n",
        "    print(\" - vocab_enhancer\")\n",
        "if tone_req:\n",
        "    print(f\" - tone_adjuster ({tone_req})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0cuy_DJ7W0I",
        "outputId": "86b7aa47-83f4-4395-9076-a4bcbc689a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence or paragraph: I am learnign ML it is fun.\n",
            "Add vocabulary enhancement? (y/n): n\n",
            "Tone (leave blank for none, e.g. formal/casual): casual\n",
            "\n",
            "Improved sentence:\n",
            " I'm learning ML. It's fun!\n",
            "\n",
            "Steps executed:\n",
            " - grammar_corrector\n",
            " - sentence_rewriter\n",
            " - tone_adjuster (casual)\n"
          ]
        }
      ]
    }
  ]
}